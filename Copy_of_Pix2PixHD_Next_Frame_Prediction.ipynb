{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Pix2PixHD Next Frame Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Daniahblog/Colab/blob/master/Copy_of_Pix2PixHD_Next_Frame_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXoBaXRDKuMV",
        "colab_type": "text"
      },
      "source": [
        "#Next Frame Prediction using Pix2PixHD\n",
        "\n",
        "By Derrick Schultz\n",
        "\n",
        "Forked repo and tutorial based on [JC Testud’s excellent repo and Medium](https://medium.com/@jctestud/video-generation-with-pix2pix-aed5b1b69f57) article."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfOexYWJX3Pt",
        "colab_type": "text"
      },
      "source": [
        "## Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K--AsrIzpH58",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cae111d7-f723-4d73-e3dc-1873cd181bc3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUvLbCJtLqaV",
        "colab_type": "text"
      },
      "source": [
        "## Install libraries and dependencies\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3dczlxhXwe6",
        "colab_type": "text"
      },
      "source": [
        "### Run this cell if you haven’t previously install Pix2PixHD in your Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQbRsmWdvjUo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "861bad05-96b3-4352-9753-96ed6631afaf"
      },
      "source": [
        "%cd /content/drive/My\\ Drive\n",
        "!mkdir nfp-colab\n",
        "%cd nfp-colab\n",
        "!git clone -b video https://github.com/dvschultz/pix2pixHD.git\n",
        "!pip install dominate\n",
        "%cd pix2pixHD/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n",
            "mkdir: cannot create directory ‘nfp-colab’: File exists\n",
            "/content/drive/My Drive/nfp-colab\n",
            "fatal: destination path 'pix2pixHD' already exists and is not an empty directory.\n",
            "Collecting dominate\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/e6/794a119963b7cfe4bd41177c8f9d4195fe901652f04189fbd2edf513c7b2/dominate-2.5.1-py2.py3-none-any.whl\n",
            "Installing collected packages: dominate\n",
            "Successfully installed dominate-2.5.1\n",
            "/content/drive/My Drive/nfp-colab/pix2pixHD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yDOMtTH42xl",
        "colab_type": "text"
      },
      "source": [
        "### Run this cell if you’ve already installed Pix2PixHD in Google Drive before"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V94ah70BxPUn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "d2e1deed-9434-4f24-d28d-bb5e8e3e6c99"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/nfp-colab/pix2pixHD/\n",
        "# !git pull\n",
        "!pip install dominate\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/nfp-colab/pix2pixHD\n",
            "Collecting dominate\n",
            "  Downloading https://files.pythonhosted.org/packages/c0/03/1ba70425be63f2aab42fbc98894fe5d90cdadd41f79bdc778b3e404cfd8f/dominate-2.5.2-py2.py3-none-any.whl\n",
            "Installing collected packages: dominate\n",
            "Successfully installed dominate-2.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzLGf05WXMFV",
        "colab_type": "text"
      },
      "source": [
        "## Extract frames from video\n",
        "\n",
        "Upload a video to either Colab or Google Drive.\n",
        "\n",
        "* `-video` is the path to the video file\n",
        "* `-name` should be a unique name (think of it like a project name)\n",
        "* `-width` and `-height` **must** to be a multiple of 32\n",
        "* `-p2pdir` leave as `.` unless you know it shouldn’t be that ;)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWRL2ty6N9LD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "3a73e1d8-b9ea-41e8-e8c2-db1ba2b6d7c3"
      },
      "source": [
        "!python extract_frames.py -video /content/Short_Video_Zoom.mp4 -name Short_Video_Zoom -p2pdir . -width 1280 -height 736"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creating the dataset structure\n",
            "ffmpeg -v 16 -i /content/Short_Video_Zoom.mp4 -q:v 2 -vf \"scale=iw*736/ih:736, crop=1280:736\" /content/drive/My\\ Drive/nfp-colab/pix2pixHD/datasets/Short_Video_Zoom/train_frames/frame-%06d.jpg -hide_banner\n",
            "extracting the frames\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL9BZkBA_QRR",
        "colab_type": "text"
      },
      "source": [
        "## Train your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X7qahzMX05u",
        "colab_type": "text"
      },
      "source": [
        "### Initial training\n",
        "\n",
        "Note: if you have a large dataset, this may timeout initially (`ValueError: __len__() should return >= 0`). Give it a minute or two and run it again.\n",
        "\n",
        "*   `--name` should be a unique name (think of it like a project name). For your sanity I recommend using the same `-name` as above.\n",
        "*   `--dataroot` should point to your dataset. This will usually be in `./datasets/[your project name]`\n",
        "\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzHBGVnUKEzE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0170846e-3a8f-46ad-ed78-943c9d8112f9"
      },
      "source": [
        "!python train_video.py --name Short_Video_Zoom --dataroot ./datasets/Short_Video_Zoom --save_epoch_freq 5 #--continue_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'train_video.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GDg3CeW_1TD",
        "colab_type": "text"
      },
      "source": [
        "### Continue Training\n",
        "To pick up from a previous training session run the same command you ran to start with and append `--continue_train` to the end of the command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5q3dE9S_5eg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "45d83093-835f-4c82-d4f1-f2126f25d040"
      },
      "source": [
        "!python train_video.py --name Short_Video_Zoom --dataroot ./datasets/Short_Video_Zoom --save_epoch_freq 5 --continue_train"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------ Options -------------\n",
            "batchSize: 1\n",
            "beta1: 0.5\n",
            "checkpoints_dir: ./checkpoints\n",
            "continue_train: True\n",
            "data_type: 32\n",
            "dataroot: ./datasets/Short_Video_Zoom\n",
            "debug: False\n",
            "display_freq: 100\n",
            "display_winsize: 512\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "fps: 24.0\n",
            "gpu_ids: [0]\n",
            "heat_seeking_lvl: 0\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: True\n",
            "label_feat: False\n",
            "label_nc: 35\n",
            "lambda_feat: 10.0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "load_pretrain: \n",
            "local_rank: 0\n",
            "lr: 0.0002\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_layers_D: 3\n",
            "n_local_enhancers: 1\n",
            "name: Short_Video_Zoom\n",
            "ndf: 64\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter: 100\n",
            "niter_decay: 100\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_ganFeat_loss: False\n",
            "no_html: False\n",
            "no_instance: False\n",
            "no_lsgan: False\n",
            "no_vgg_loss: False\n",
            "norm: instance\n",
            "num_D: 2\n",
            "output_nc: 3\n",
            "phase: train\n",
            "pool_size: 0\n",
            "print_freq: 100\n",
            "pstart: 1\n",
            "pstop: 1\n",
            "resize_or_crop: scale_width\n",
            "save_epoch_freq: 5\n",
            "save_latest_freq: 1000\n",
            "scheduled_sampling: False\n",
            "serial_batches: False\n",
            "ss_recursion_prob: 0.2\n",
            "start_from: video\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "verbose: False\n",
            "video_mode: False\n",
            "which_epoch: latest\n",
            "zoom_lvl: 0\n",
            "-------------- End ----------------\n",
            "Resuming from epoch 201 at iteration 0\n",
            "CustomDatasetDataLoader\n",
            "dataset [FrameDataset] was created\n",
            "FrameDataset initialized from: ./datasets/Short_Video_Zoom/train_frames\n",
            "contains 123 frames, 122 consecutive pairs\n",
            "#training images = 122\n",
            "\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100% 548M/548M [00:04<00:00, 132MB/s]\n",
            "create web directory ./checkpoints/Short_Video_Zoom/web...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5jzHVWXGa7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jly_3OyBoGg2",
        "colab_type": "text"
      },
      "source": [
        "#Generating Videos\n",
        "\n",
        "To generate a video from your completed model, run the `generate_video.py` script. I recommend keeping the `--name` and `--dataroot` arguments the same.\n",
        "\n",
        "There are a number of additional arguments you’ll need to include in this command:\n",
        "\n",
        "\n",
        "*   `--fps` frame rate for your video\n",
        "*   `--how_many` how many frames you want to create (this + fps = video length)\n",
        "*   `--which_epoch` which epoch you want to generate videos from (note: if you choose `133` but there’s no epoch 133 model file, this will throw an error)\n",
        "*   `--start_from` by default your video will start predicting images from the 60th frame of your training set. You can pass in the path to a different frame to have it start from that frame\n",
        "\n",
        "I recommend playing with both the `--which_epoch` and `--start_from` arguments as you can get dramatically different results by changing in the inputs here.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INVUtG-pt_F6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "204aadb2-b395-47bc-eefb-db7c97ad2bf5"
      },
      "source": [
        "!python generate_video.py --name Short_Video_Zoom --dataroot ./datasets/Short_Video_Zoom  --fps 24 --how_many 600 --which_epoch latest "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------ Options -------------\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 1\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "data_type: 32\n",
            "dataroot: ./datasets/Short_Video_Zoom\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "fps: 24.0\n",
            "gpu_ids: [0]\n",
            "heat_seeking_lvl: 0\n",
            "how_many: 600\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 35\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_local_enhancers: 1\n",
            "name: Short_Video_Zoom\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: False\n",
            "norm: instance\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "phase: test\n",
            "pstart: 1\n",
            "pstop: 1\n",
            "resize_or_crop: scale_width\n",
            "results_dir: ./results/\n",
            "scheduled_sampling: False\n",
            "serial_batches: False\n",
            "ss_recursion_prob: 0.2\n",
            "start_from: video\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "verbose: False\n",
            "video_mode: False\n",
            "which_epoch: latest\n",
            "zoom_lvl: 0\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [FrameDataset] was created\n",
            "FrameDataset initialized from: ./datasets/Short_Video_Zoom/test_frames\n",
            "contains 60 frames, 59 consecutive pairs\n",
            "\n",
            "100% 600/600 [03:02<00:00,  3.29it/s]\n",
            "ffmpeg -v 16 -framerate 24 -i ./checkpoints/Short_Video_Zoom/frames/frame-%05d.jpg -ss 1 -q:v 2 -filter:v \"crop=1280:720:0:16\" ./checkpoints/Short_Video_Zoom/output/epoch-latest_Short_Video_Zoom_25.0-s_24.0-fps.mp4\n",
            "building video from frames\n",
            "video ready:\n",
            "./checkpoints/Short_Video_Zoom/output/epoch-latest_Short_Video_Zoom_25.0-s_24.0-fps.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiaLMDmdDG3t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "2191c96c-03fa-48e1-8013-ab130e6df9e0"
      },
      "source": [
        "import os\n",
        "\n",
        "def processFolder(folder, epoch = 10, frameCount = 240, skipCount = 1):\n",
        "  files = os.listdir(folder)\n",
        "\n",
        "  count = 0\n",
        "  for f in files:\n",
        "    \n",
        "    if (count % skipCount == 0):\n",
        "      print(f)\n",
        "      if epoch == 'latest':\n",
        "        command = 'python generate_video.py --name glitch_white_circle --dataroot ./datasets/glitch-circle-white_dataset/ --fps 60 --how_many %i --which_epoch latest --start_from %s/%s' % ( frameCount, folder, f)\n",
        "      else:\n",
        "        command = 'python generate_video.py --name glitch_white_circle --dataroot ./datasets/glitch-circle-white_dataset/ --fps 24 --how_many %i --which_epoch %i --start_from %s/%s' % ( frameCount, epoch, folder, f)\n",
        "      os.system(command)\n",
        "    count += 1\n",
        "\n",
        "processFolder('./datasets/fuck-white/train_frames',1,600,3050)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frame-018504.jpg\n",
            "frame-015525.jpg\n",
            "frame-012746.jpg\n",
            "frame-009603.jpg\n",
            "frame-006972.jpg\n",
            "frame-004082.jpg\n",
            "frame-001186.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}